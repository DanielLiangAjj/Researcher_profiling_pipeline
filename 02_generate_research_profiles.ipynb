{
 "cells": [
  {
   "cell_type": "code",
   "id": "7f8466d4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-22T21:27:04.557980Z",
     "start_time": "2026-01-22T21:27:03.127045Z"
    }
   },
   "source": "# Standard library imports\nimport os\nimport sys\nimport pickle\nimport time\nimport warnings\n\n# Data processing\nimport numpy as np\nimport pandas as pd\n\n# Machine learning\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom kneed import KneeLocator\n\n# Utilities\nfrom collections import defaultdict\nfrom tqdm import tqdm\n\n# OpenAI\nfrom openai import OpenAI\n\nwarnings.filterwarnings(\"ignore\")",
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "id": "11b8rqc1tzb",
   "source": "# Research Profile Generation Pipeline\n\nThis notebook processes MeSH terms from researcher publications and generates natural language research profiles using GPT-4.\n\n**Pipeline Steps:**\n1. Load MeSH tree hierarchy\n2. Process and expand MeSH terms to ancestors\n3. Filter low-frequency terms\n4. Categorize terms (Health Domain vs Methods)\n5. Remove meaningless terms\n6. Compute TF-IDF scores\n7. Select top terms using elbow detection\n8. Generate summaries with GPT-4\n9. Combine and export final profiles",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "3f31ecff",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-22T21:27:04.579676Z",
     "start_time": "2026-01-22T21:27:04.560937Z"
    }
   },
   "source": "# =============================================================================\n# CONFIGURATION - Set your API key here\n# =============================================================================\nopenai_api_key = ''  # Enter your OpenAI API key",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "c0lxcfjk7a7",
   "source": "## 1. Function Definitions\n\nThe following cells define all the helper functions used in the pipeline.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "7bbc3617",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-22T21:27:04.595093Z",
     "start_time": "2026-01-22T21:27:04.581665Z"
    }
   },
   "source": "\ndef load_mesh_trees(meshtree_file):\n    \"\"\"\n    Load a MeSH tree file and build ID-to-name and name-to-ID mappings.\n\n    Parameters\n    ----------\n    meshtree_file : str\n        Path to the MeSH tree file (e.g., \"data/reference_files/mesh_tree_hierarchy.bin\").\n        Each line in the file is expected to be formatted as:\n            <term>;<tree_id>\n\n    Returns\n    -------\n    mesh_id2name : dict\n        Dictionary mapping MeSH tree IDs (e.g., \"A01.111\") to term names.\n    \n    mesh_name2id : dict of lists\n        Dictionary mapping MeSH term names to a list of associated MeSH IDs.\n\n    Notes\n    -----\n    The function also injects two additional MeSH-like IDs:\n        NEWID1 → Female  \n        NEWID2 → Male\n    \"\"\"\n    mesh_id2name = {}\n    mesh_name2id = defaultdict(list)\n\n\n    with open(meshtree_file, \"r\") as ftree:\n        for line in ftree:\n            term, tree_id = line.strip().split(\";\")\n\n            mesh_id2name[tree_id] = term\n            mesh_name2id[term].append(tree_id)\n\n    # Add the two extra synthetic entries\n    extra_entries = {\n        'NEWID1': 'Female',\n        'NEWID2': 'Male'\n    }\n\n    for mid, term in extra_entries.items():\n        mesh_id2name[mid] = term\n        mesh_name2id[term] = [mid]\n\n    return mesh_id2name, mesh_name2id",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "27b3b94d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-22T21:27:04.612848Z",
     "start_time": "2026-01-22T21:27:04.597605Z"
    }
   },
   "source": [
    "def process_mesh_terms(csv_file, mesh_id2name, mesh_name2id):\n",
    "    \"\"\"\n",
    "    Process researcher MeSH terms into hierarchical MeSH ancestor codes.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    csv_file : str\n",
    "        Path to the CSV file containing researcher MeSH terms.\n",
    "        Expected columns:\n",
    "            - First Name\n",
    "            - Last Name\n",
    "            - PMID\n",
    "            - Person ID\n",
    "            - mesh_term   (format: \"Term / Subheading\" or just \"Term\")\n",
    "\n",
    "    mesh_id2name : dict\n",
    "        Mapping from MeSH ID → MeSH term name.\n",
    "        Example: {\"A01.111\": \"Heart\"}.\n",
    "\n",
    "    mesh_name2id : dict or defaultdict(list)\n",
    "        Mapping from MeSH term name → list of associated MeSH IDs.\n",
    "        Example: {\"Heart\": [\"A01.111\", \"A01.112\"]}.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    df_mesh_term : pandas.DataFrame\n",
    "        A cleaned dataframe with one row per:\n",
    "            (author × PMID × ancestor MeSH term)\n",
    "        Columns:\n",
    "            First Name, Last Name, PMID,\n",
    "            Person ID, ancestor_mesh_term\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    • Handles MeSH terms with and without subheadings.\n",
    "    • Automatically assigns:\n",
    "          Female → NEWID1\n",
    "          Male   → NEWID2\n",
    "    • Builds full hierarchical ancestor chains for every MeSH ID.\n",
    "    \"\"\"\n",
    "\n",
    "    # --------------------------------------------------\n",
    "    # Helper function: split mesh term into main + subheadings\n",
    "    # --------------------------------------------------\n",
    "    def split_mesh_term(mesh_term):\n",
    "        parts = mesh_term.split(\" / \")\n",
    "        if len(parts) > 1:\n",
    "            return parts[0], parts[1:]\n",
    "        return parts[0], []\n",
    "\n",
    "    # --------------------------------------------------\n",
    "    # Helper function: recursively find ancestors\n",
    "    # --------------------------------------------------\n",
    "    def find_mesh_term_ancestors(tid, ancestor_ids):\n",
    "        ancestors = []\n",
    "        mesh_name = mesh_id2name[tid]\n",
    "\n",
    "        # Add current term\n",
    "        ancestors.append(mesh_name)\n",
    "\n",
    "        # Get all IDs associated with the same MeSH term\n",
    "        ids_for_name = mesh_name2id[mesh_name]\n",
    "        ancestor_ids += ids_for_name\n",
    "\n",
    "        # Parent IDs = chop off last part of MeSH tree number\n",
    "        parent_ids = [\".\".join(mid.split(\".\")[:-1]) for mid in ids_for_name]\n",
    "\n",
    "        for pid in parent_ids:\n",
    "            if pid and pid not in ancestor_ids:\n",
    "                new_ancestors, ancestor_ids = find_mesh_term_ancestors(pid, ancestor_ids)\n",
    "                ancestors.extend(new_ancestors)\n",
    "                ancestors = list(set(ancestors))  # unique\n",
    "        return ancestors, ancestor_ids\n",
    "\n",
    "    # --------------------------------------------------\n",
    "    # Get only ancestor names\n",
    "    # --------------------------------------------------\n",
    "    def create_mesh_term_hierarchical_codes(tid):\n",
    "        ancestors, _ = find_mesh_term_ancestors(tid, [])\n",
    "        return ancestors\n",
    "\n",
    "    # --------------------------------------------------\n",
    "    # Load CSV\n",
    "    # --------------------------------------------------\n",
    "    df_mesh = pd.read_csv(csv_file)\n",
    "\n",
    "    # Split \"Term / Subheading\"\n",
    "    df_mesh['mesh_term_only'], df_mesh['mesh_subheading'] = zip(\n",
    "        *df_mesh['MeSH Term'].apply(split_mesh_term)\n",
    "    )\n",
    "\n",
    "    # Map main term → ID(s)\n",
    "    df_mesh['mesh_term_only_id'] = df_mesh['mesh_term_only'].apply(lambda x: mesh_name2id[x])\n",
    "\n",
    "    # Assign new synthetic IDs for Female / Male\n",
    "    df_mesh.loc[df_mesh['mesh_term_only'] == 'Female', 'mesh_term_only_id'] = 'NEWID1'\n",
    "    df_mesh.loc[df_mesh['mesh_term_only'] == 'Male',   'mesh_term_only_id'] = 'NEWID2'\n",
    "\n",
    "    # Expand list of IDs to one per row\n",
    "    df_mesh = df_mesh.explode(\"mesh_term_only_id\")\n",
    "\n",
    "    # Increase recursion depth (important)\n",
    "    sys.setrecursionlimit(5000)\n",
    "\n",
    "    # Compute full MeSH ancestor hierarchy\n",
    "    df_mesh['ancestor_mesh_term'] = df_mesh['mesh_term_only_id'].apply(\n",
    "        create_mesh_term_hierarchical_codes\n",
    "    )\n",
    "\n",
    "    # Expand ancestors to one per row\n",
    "    df_mesh = df_mesh.explode('ancestor_mesh_term')\n",
    "\n",
    "    # Select final output columns\n",
    "    df_mesh = df_mesh[\n",
    "        ['First Name', 'Last Name', 'PMID',\n",
    "         'Person ID', 'ancestor_mesh_term']\n",
    "    ]\n",
    "\n",
    "    # Remove duplicates\n",
    "    df_mesh.drop_duplicates(inplace=True)\n",
    "\n",
    "    return df_mesh\n"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "id": "03b9a0cb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-22T21:27:04.627710Z",
     "start_time": "2026-01-22T21:27:04.615366Z"
    }
   },
   "source": [
    "\n",
    "def filter_low_frequency_mesh_terms(df_mesh_term, min_frequency=2):\n",
    "    \"\"\"\n",
    "    Filter out MeSH ancestor terms that occur less than a specified frequency\n",
    "    for each researcher.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df_mesh_term : pandas.DataFrame\n",
    "        DataFrame containing at least:\n",
    "            - Person ID\n",
    "            - ancestor_mesh_term\n",
    "\n",
    "    min_frequency : int, optional (default = 2)\n",
    "        Minimum number of occurrences required for a researcher to keep a term.\n",
    "        Terms occurring fewer times than this per Person ID are removed.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    df_filtered : pandas.DataFrame\n",
    "        DataFrame with columns:\n",
    "            Person ID, ancestor_mesh_term, count\n",
    "        containing only the MeSH terms that meet the frequency threshold.\n",
    "    \"\"\"\n",
    "\n",
    "    # Compute frequency of each ancestor term per researcher\n",
    "    df_freq = (\n",
    "        df_mesh_term\n",
    "        .groupby('Person ID')['ancestor_mesh_term']\n",
    "        .value_counts()\n",
    "        .rename('count')\n",
    "        .reset_index()\n",
    "    )\n",
    "\n",
    "    # Keep terms at or above frequency threshold\n",
    "    df_filtered = df_freq[df_freq['count'] >= min_frequency]\n",
    "\n",
    "    return df_filtered\n"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "id": "37419a45",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-22T21:27:04.644985Z",
     "start_time": "2026-01-22T21:27:04.630224Z"
    }
   },
   "source": "\ndef categorize_mesh_terms(\n    df_mesh_term_freq,\n    mesh_id2name,\n    mesh_name2id,\n    class_file=\"data/reference_files/mesh_category_classification.xlsx\"\n):\n    \"\"\"\n    Categorize MeSH ancestor terms into 'Health Domain' (H) and 'Method' (M)\n    classes using a manually tagged level-01 class file, then propagate\n    categories to child terms based on MeSH parent–child relationships.\n\n    Parameters\n    ----------\n    df_mesh_term_freq : pandas.DataFrame\n        Output of filter_low_frequency_mesh_terms(), must contain:\n            - ancestor_mesh_term\n\n    mesh_id2name : dict\n        Mapping MeSH ID -> MeSH term name\n\n    mesh_name2id : dict or defaultdict(list)\n        Mapping MeSH term name -> list of MeSH IDs\n\n    class_file : str\n        Excel file mapping MeSH terms to top-level class labels.\n        Must contain:\n            - 'name'  (MeSH term)\n            - 'Class' ('H' or 'M')\n\n    Returns\n    -------\n    mesh_names_health_domain : list\n        All MeSH term names categorized under Health Domain (H)\n\n    mesh_names_method : list\n        All MeSH term names categorized under Methods (M)\n    \"\"\"\n\n    # ------------------------------\n    # Load class definitions\n    # ------------------------------\n    df_class = pd.read_excel(class_file, index_col=0)\n\n    mesh_names_health_domain_manual = list(df_class[df_class['Class'] == 'H']['name'])\n    mesh_names_method_manual = list(df_class[df_class['Class'] == 'M']['name'])\n\n    # -------------------------------------------\n    # Get all unique ancestor terms from freq df\n    # -------------------------------------------\n    df_temp = df_mesh_term_freq[['ancestor_mesh_term']].drop_duplicates()\n\n    # Map term → IDs\n    df_temp['term_id'] = df_temp['ancestor_mesh_term'].apply(lambda x: mesh_name2id[x])\n    df_temp = df_temp.explode('term_id')\n\n    # Sort IDs by length so parents come first\n    df_temp['length'] = df_temp['term_id'].apply(len)\n    df_temp = df_temp.sort_values(by='length').drop_duplicates()\n\n    term_ids = list(df_temp['term_id'])\n\n    # -------------------------------------------\n    # Initialize category lists\n    # -------------------------------------------\n    mesh_names_health_domain = mesh_names_health_domain_manual.copy()\n    mesh_names_method = mesh_names_method_manual.copy()\n\n    # -------------------------------------------\n    # Categorize by tracing parent IDs\n    # -------------------------------------------\n    for tid in term_ids:\n        term_name = mesh_id2name[tid]\n\n        # Skip terms already categorized manually\n        if (term_name in mesh_names_health_domain_manual) or (term_name in mesh_names_method):\n            continue\n\n        parts = tid.split(\".\")\n        if len(parts) >= 2:\n            parent_id = \".\".join(parts[:-1])\n            parent_name = mesh_id2name[parent_id]\n\n            # Inherit health domain from parent\n            if parent_name in mesh_names_health_domain:\n                mesh_names_health_domain.append(term_name)\n\n            # Inherit method class from parent\n            if parent_name in mesh_names_method:\n                mesh_names_method.append(term_name)\n\n    # Remove duplicates\n    mesh_names_health_domain = list(set(mesh_names_health_domain))\n    mesh_names_method = list(set(mesh_names_method))\n\n    return mesh_names_health_domain, mesh_names_method",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "56f1f0b8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-22T21:27:04.662940Z",
     "start_time": "2026-01-22T21:27:04.647056Z"
    }
   },
   "source": "# Terms that are too broad or non-informative to be useful\nMEANINGLESS_MESH_TERMS = [\n    'Eukaryota', 'Animals', 'Chordata', 'Vertebrates', 'Mammals', 'Eutheria',\n    'Primates', 'Haplorhini', 'Catarrhini', 'Hominidae', 'Humans',\n    'Natural Science Disciplines', 'Science', 'Research', 'Methods',\n    'Investigative Techniques', 'Persons', 'Health Occupations',\n    'Equipment and Supplies', 'Electrical Equipment and Supplies',\n    'Biomedical Research', 'Household Products', 'Photography',\n    'Financial Management', 'life', 'Medicine', 'Diseases'\n]\n\n\ndef remove_meaningless_mesh_terms(df_mesh_term_freq, mesh_id2name):\n    \"\"\"\n    Remove overly broad or non-informative MeSH terms.\n\n    Filters out:\n    - Predefined list of generic terms (e.g., \"Humans\", \"Animals\", \"Science\")\n    - Geographic terms (MeSH IDs starting with 'Z01')\n\n    Parameters\n    ----------\n    df_mesh_term_freq : pandas.DataFrame\n        DataFrame with ancestor_mesh_term column.\n    mesh_id2name : dict\n        Mapping from MeSH ID to term name.\n\n    Returns\n    -------\n    pandas.DataFrame\n        Filtered DataFrame with meaningless terms removed.\n    \"\"\"\n    # Start with predefined list\n    terms_to_remove = MEANINGLESS_MESH_TERMS.copy()\n    \n    # Add geographic terms (Z01.*)\n    for mesh_id, name in mesh_id2name.items():\n        if mesh_id.startswith('Z01'):\n            terms_to_remove.append(name)\n\n    return df_mesh_term_freq[\n        ~df_mesh_term_freq['ancestor_mesh_term'].isin(terms_to_remove)\n    ].copy()",
   "outputs": [],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "id": "62dddd0f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-22T21:27:04.677679Z",
     "start_time": "2026-01-22T21:27:04.664764Z"
    }
   },
   "source": "def export_mesh_term_frequency_by_category(\n        df_mesh,\n        df_mesh_term_freq,\n        mesh_names_health_domain,\n        mesh_names_method,\n        directory\n    ):\n    \"\"\"\n    Export MeSH term frequency tables for Health Domain and Method categories.\n\n    Parameters\n    ----------\n    df_mesh : pandas.DataFrame\n        Must contain: First Name, Last Name, Person ID\n    df_mesh_term_freq : pandas.DataFrame\n        Must contain: Person ID, ancestor_mesh_term, count\n    mesh_names_health_domain : list\n        List of MeSH terms classified as Health Domain.\n    mesh_names_method : list\n        List of MeSH terms classified as Methods.\n    directory : str\n        Folder where Excel files will be saved.\n\n    Returns\n    -------\n    tuple\n        (health_domain_list, method_list) - Term frequencies as lists.\n    \"\"\"\n    df_person = df_mesh[['First Name', 'Last Name', 'Person ID']].drop_duplicates()\n\n    # Filter by category\n    df_health = df_mesh_term_freq[\n        df_mesh_term_freq['ancestor_mesh_term'].isin(mesh_names_health_domain)\n    ].merge(df_person, on='Person ID')\n\n    df_method = df_mesh_term_freq[\n        df_mesh_term_freq['ancestor_mesh_term'].isin(mesh_names_method)\n    ].merge(df_person, on='Person ID')\n\n    # Save to Excel\n    os.makedirs(directory, exist_ok=True)\n    df_health.to_excel(os.path.join(directory, \"mesh_term_freq_per_faculty_HealthDomain.xlsx\"), index=False)\n    df_method.to_excel(os.path.join(directory, \"mesh_term_freq_per_faculty_Method.xlsx\"), index=False)\n\n    return df_health.values.tolist(), df_method.values.tolist()",
   "outputs": [],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "id": "bdf142d6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-22T21:27:04.691867Z",
     "start_time": "2026-01-22T21:27:04.679954Z"
    }
   },
   "source": "def build_researcher_mesh_string(mesh_term_freq_list):\n    \"\"\"\n    Build frequency-weighted term strings for TF-IDF input.\n    \n    Each term is repeated according to its frequency count.\n    Example: If \"Heart\" appears 3 times -> \"Heart;Heart;Heart\"\n\n    Parameters\n    ----------\n    mesh_term_freq_list : list of lists\n        Each row: [Person ID, term, freq, ...]\n\n    Returns\n    -------\n    dict\n        Mapping: Person ID -> \"term;term;term2;term2;...\"\n    \"\"\"\n    dict_researcher_mesh = defaultdict(str)\n\n    for row in mesh_term_freq_list:\n        person_id, term, freq = row[:3]\n        dict_researcher_mesh[person_id] += (term + \";\") * int(freq)\n\n    # Remove trailing semicolons\n    return {pid: terms.rstrip(\";\") for pid, terms in dict_researcher_mesh.items()}",
   "outputs": [],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "id": "725ddab8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-22T21:27:04.711808Z",
     "start_time": "2026-01-22T21:27:04.694279Z"
    }
   },
   "source": "def run_mesh_tfidf(dict_researcher_mesh, df_person, directory, postfix=\"HealthDomain\"):\n    \"\"\"\n    Compute TF-IDF scores for researcher MeSH term profiles.\n\n    Parameters\n    ----------\n    dict_researcher_mesh : dict\n        Mapping: Person ID -> \"term1;term1;term2;...\" (frequency-weighted)\n    df_person : pandas.DataFrame\n        Contains: Person ID, First Name, Last Name\n    directory : str\n        Output folder for CSV files.\n    postfix : str\n        Label for output files (\"HealthDomain\" or \"Method\").\n\n    Returns\n    -------\n    pandas.DataFrame\n        TF-IDF scores in long format (term, score, name).\n    \"\"\"\n    def custom_tokenizer(text):\n        return [token.strip() for token in text.split(';') if token.strip()]\n\n    corpus = list(dict_researcher_mesh.values())\n    faculty_ids = list(dict_researcher_mesh.keys())\n\n    # Compute TF-IDF\n    vectorizer = TfidfVectorizer(tokenizer=custom_tokenizer)\n    X = vectorizer.fit_transform(corpus)\n\n    # Convert to long-format DataFrame\n    df_tfidf = pd.DataFrame(X.toarray())\n    df_tfidf[\"Person ID\"] = faculty_ids\n    df_tfidf.set_index(\"Person ID\", inplace=True)\n\n    df_tfidf = df_tfidf.T\n    df_tfidf[\"mesh_term\"] = vectorizer.get_feature_names_out()\n    df_tfidf.set_index(\"mesh_term\", inplace=True)\n\n    df_tfidf = pd.DataFrame(df_tfidf.unstack()).reset_index()\n    df_tfidf.rename(columns={\"level_0\": \"Person ID\", 0: \"tfidf_score\"}, inplace=True)\n\n    # Add researcher names\n    df_tfidf = df_tfidf.merge(df_person, on=\"Person ID\")\n    df_tfidf[\"name\"] = df_tfidf[\"First Name\"] + \" \" + df_tfidf[\"Last Name\"]\n    df_tfidf.drop([\"Person ID\", \"First Name\", \"Last Name\"], axis=1, inplace=True)\n\n    # Save output\n    os.makedirs(directory, exist_ok=True)\n    df_tfidf.to_csv(os.path.join(directory, f\"term_per_researcher_tfidf_{postfix}.csv\"), index=False)\n\n    return df_tfidf",
   "outputs": [],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "id": "cb294150",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-22T21:27:04.729842Z",
     "start_time": "2026-01-22T21:27:04.714356Z"
    }
   },
   "source": "def generate_gpt4_response(content, print_output=False):\n    \"\"\"\n    Send a prompt to GPT-4 and return the generated response.\n    \n    Parameters\n    ----------\n    content : str\n        The prompt to send to GPT-4.\n    print_output : bool\n        If True, print the full API response for debugging.\n    \n    Returns\n    -------\n    str or None\n        The generated text, or None if an error occurred.\n    \"\"\"\n    client = OpenAI(api_key=openai_api_key)\n    \n    try:\n        completions = client.chat.completions.create(\n            model=\"gpt-4o\",\n            temperature=0,  # Deterministic output\n            top_p=0.1,      # Focused sampling\n            n=1,\n            messages=[\n                {'role': 'system', 'content': 'You are a dean of a college.'},\n                {'role': 'user', 'content': content},\n            ]\n        )\n\n        if print_output:\n            print(completions)\n\n        return completions.choices[0].message.content\n    \n    except Exception as e:\n        print(f\"An error occurred: {e}\")\n        return None",
   "outputs": [],
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "id": "6abdf015",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-22T21:27:04.747168Z",
     "start_time": "2026-01-22T21:27:04.731831Z"
    }
   },
   "source": "def generate_research_focus_summaries(postfix, directory, generate_gpt4_response, df_person, elbow_S=5):\n    \"\"\"\n    Generate research focus summaries for each researcher using GPT-4.\n\n    Uses TF-IDF scores to select top terms via elbow-point detection,\n    then sends them to GPT-4 for natural language summarization.\n\n    Parameters\n    ----------\n    postfix : str\n        Category label (\"Method\" or \"HealthDomain\").\n    directory : str\n        Folder for input/output files.\n    generate_gpt4_response : callable\n        Function to call GPT-4 API.\n    df_person : pandas.DataFrame\n        Researcher info (Person ID, First Name, Last Name).\n    elbow_S : int\n        Sensitivity parameter for KneeLocator (default: 5).\n\n    Returns\n    -------\n    tuple\n        (dict_terms, dict_summaries) - Selected terms and generated summaries.\n    \"\"\"\n    # Load TF-IDF scores\n    file_path = os.path.join(directory, f\"term_per_researcher_tfidf_{postfix}.csv\")\n    df_tfidf = pd.read_csv(file_path)\n    df_tfidf = df_tfidf[df_tfidf[\"tfidf_score\"] > 0]\n\n    # Build researcher -> {term: score} mapping\n    dict_mesh_tfidf = (\n        df_tfidf.groupby(\"name\")\n        .apply(lambda x: dict(zip(x[\"mesh_term\"], x[\"tfidf_score\"])))\n        .to_dict()\n    )\n\n    dict_terms = {}\n    dict_summaries = {}\n\n    for researcher_name in tqdm(dict_mesh_tfidf.keys()):\n        # Sort terms by TF-IDF score\n        df_temp = df_tfidf[df_tfidf[\"name\"] == researcher_name].copy()\n        df_temp.sort_values(\"tfidf_score\", ascending=False, inplace=True)\n        df_temp[\"rank\"] = np.arange(len(df_temp))\n\n        # Find elbow point for term selection\n        kneedle = KneeLocator(\n            df_temp[\"rank\"], df_temp[\"tfidf_score\"],\n            S=elbow_S, curve=\"convex\", direction=\"decreasing\"\n        )\n        \n        # Fallback: top 5% or at least 3 terms\n        knee_point = kneedle.knee if kneedle.knee else max(3, int(0.05 * len(df_temp)))\n        \n        # Select top terms\n        selected_terms = list(df_temp.iloc[:knee_point][\"mesh_term\"])\n        dict_terms[researcher_name] = \"; \".join(selected_terms)\n\n        # Generate GPT-4 summary\n        prompt = (\n            f\"Help me summarize this group of phrases into 1 sentence as a research focus:\\n\"\n            f\"{dict_terms[researcher_name]}\\n\"\n            f\"Please start with: The research focus is on\"\n        )\n\n        summary = None\n        while summary is None:\n            summary = generate_gpt4_response(prompt)\n            if summary is None:\n                print(f\"GPT-4 failed, retrying...\")\n                time.sleep(3)\n\n        # Adjust prefix based on category\n        if postfix == \"Method\":\n            summary = summary.replace(\"The research focus is on\", \"This researcher has mainly contributed to\")\n        else:\n            summary = summary.replace(\"The research focus is on\", \"This researcher mainly focused on\")\n\n        dict_summaries[researcher_name] = summary\n\n    # Save results\n    with open(os.path.join(directory, f\"dict_terms_for_a_researcher_for_focus{postfix}.pickle\"), \"wb\") as f:\n        pickle.dump(dict_terms, f, protocol=pickle.HIGHEST_PROTOCOL)\n    with open(os.path.join(directory, f\"dict_research_focus_for_a_researcher_{postfix}.pickle\"), \"wb\") as f:\n        pickle.dump(dict_summaries, f, protocol=pickle.HIGHEST_PROTOCOL)\n\n    return dict_terms, dict_summaries",
   "outputs": [],
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "id": "d76ff275",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-22T21:27:04.760238Z",
     "start_time": "2026-01-22T21:27:04.748838Z"
    }
   },
   "source": "def combine_research_focus_summaries(\n        directory,\n        postfix_hd=\"HealthDomain\",\n        postfix_m=\"Method\",\n        output_excel=\"Research_summary_byMesh.xlsx\"\n    ):\n    \"\"\"\n    Combine Health Domain and Method summaries into a single research profile.\n\n    Parameters\n    ----------\n    directory : str\n        Folder containing the pickle files.\n    postfix_hd : str\n        Postfix for Health Domain pickle file.\n    postfix_m : str\n        Postfix for Method pickle file.\n    output_excel : str\n        Output Excel filename.\n\n    Returns\n    -------\n    pandas.DataFrame\n        Combined profiles with columns: Researcher_name, Research_direction\n    \"\"\"\n    # Load Health Domain summaries\n    with open(os.path.join(directory, f\"dict_research_focus_for_a_researcher_{postfix_hd}.pickle\"), \"rb\") as f:\n        dict_hd = pickle.load(f)\n    df_hd = pd.DataFrame.from_dict(dict_hd, orient=\"index\").reset_index()\n    df_hd.columns = [\"Researcher_name\", \"Research_summary_hd\"]\n\n    # Load Method summaries\n    with open(os.path.join(directory, f\"dict_research_focus_for_a_researcher_{postfix_m}.pickle\"), \"rb\") as f:\n        dict_m = pickle.load(f)\n    df_m = pd.DataFrame.from_dict(dict_m, orient=\"index\").reset_index()\n    df_m.columns = [\"Researcher_name\", \"Research_summary_m\"]\n\n    # Merge and combine\n    df = df_hd.merge(df_m, on=\"Researcher_name\", how=\"outer\").fillna(\"\")\n    df[\"Research_direction\"] = (df[\"Research_summary_hd\"] + \"\\n\" + df[\"Research_summary_m\"]).str.strip(\"\\n\")\n\n    df_final = df[[\"Researcher_name\", \"Research_direction\"]]\n    df_final.to_excel(os.path.join(directory, output_excel), index=False)\n\n    return df_final",
   "outputs": [],
   "execution_count": 13
  },
  {
   "cell_type": "markdown",
   "id": "d54ee96k8v",
   "source": "## 2. Pipeline Execution\n\nThe following cells execute the pipeline step by step.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "038e0883",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-22T21:27:04.772223Z",
     "start_time": "2026-01-22T21:27:04.761991Z"
    }
   },
   "source": "# =============================================================================\n# FILE PATHS\n# =============================================================================\ndirectory = \"results/final_result\"\ninput_file = \"data/output_sample/preprocess/filtered_publications.csv\"",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "19290c23",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-22T21:27:04.868065Z",
     "start_time": "2026-01-22T21:27:04.773927Z"
    }
   },
   "source": "# Step 1: Load MeSH tree hierarchy\nmeshtree_file = \"data/reference_files/mesh_tree_hierarchy.bin\"\nmesh_id2name, mesh_name2id = load_mesh_trees(meshtree_file)\nprint(f\"Loaded {len(mesh_id2name)} MeSH terms\")",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "04e18282",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-22T21:27:05.045073Z",
     "start_time": "2026-01-22T21:27:04.870656Z"
    }
   },
   "source": "# Step 2: Process MeSH terms and expand to ancestors\ndf_mesh_term = process_mesh_terms(input_file, mesh_id2name, mesh_name2id)\nprint(f\"Processed {len(df_mesh_term)} term-publication pairs\")\ndf_mesh_term.head()",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 9652 term-publication pairs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "  First Name Last Name      PMID  Person ID ancestor_mesh_term\n",
       "0    Chunhua      Weng  38838949          1           Eutheria\n",
       "0    Chunhua      Weng  38838949          1            Mammals\n",
       "0    Chunhua      Weng  38838949          1           Chordata\n",
       "0    Chunhua      Weng  38838949          1            Animals\n",
       "0    Chunhua      Weng  38838949          1          Hominidae"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>First Name</th>\n",
       "      <th>Last Name</th>\n",
       "      <th>PMID</th>\n",
       "      <th>Person ID</th>\n",
       "      <th>ancestor_mesh_term</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Chunhua</td>\n",
       "      <td>Weng</td>\n",
       "      <td>38838949</td>\n",
       "      <td>1</td>\n",
       "      <td>Eutheria</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Chunhua</td>\n",
       "      <td>Weng</td>\n",
       "      <td>38838949</td>\n",
       "      <td>1</td>\n",
       "      <td>Mammals</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Chunhua</td>\n",
       "      <td>Weng</td>\n",
       "      <td>38838949</td>\n",
       "      <td>1</td>\n",
       "      <td>Chordata</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Chunhua</td>\n",
       "      <td>Weng</td>\n",
       "      <td>38838949</td>\n",
       "      <td>1</td>\n",
       "      <td>Animals</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Chunhua</td>\n",
       "      <td>Weng</td>\n",
       "      <td>38838949</td>\n",
       "      <td>1</td>\n",
       "      <td>Hominidae</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "id": "c459d83f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-22T21:27:05.090047Z",
     "start_time": "2026-01-22T21:27:05.059229Z"
    }
   },
   "source": "# Step 3: Filter low-frequency terms (keep terms appearing 2+ times)\ndf_mesh_term_freq = filter_low_frequency_mesh_terms(df_mesh_term, min_frequency=2)\nprint(f\"Kept {len(df_mesh_term_freq)} term-researcher pairs after frequency filtering\")",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kept 559 term-researcher pairs after frequency filtering\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "id": "e99e0b11",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-22T21:27:05.661521Z",
     "start_time": "2026-01-22T21:27:05.135847Z"
    }
   },
   "source": "# Step 4: Categorize terms into Health Domain vs Methods\nmesh_names_health_domain, mesh_names_method = categorize_mesh_terms(\n    df_mesh_term_freq,\n    mesh_id2name,\n    mesh_name2id,\n    class_file=\"data/reference_files/mesh_category_classification.xlsx\"\n)\nprint(f\"Health Domain terms: {len(mesh_names_health_domain)}\")\nprint(f\"Method terms: {len(mesh_names_method)}\")",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "b4eb2185",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-22T21:27:06.001791Z",
     "start_time": "2026-01-22T21:27:05.963458Z"
    }
   },
   "source": "# Step 5: Remove meaningless/overly broad terms\ndf_mesh_term_freq = remove_meaningless_mesh_terms(df_mesh_term_freq, mesh_id2name)\nprint(f\"Remaining terms after removing meaningless: {len(df_mesh_term_freq)}\")",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remaining terms after removing meaningless: 527\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "cell_type": "code",
   "id": "aa3fb96e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-22T21:27:06.132450Z",
     "start_time": "2026-01-22T21:27:06.044771Z"
    }
   },
   "source": "# Step 6: Export term frequencies by category\nmesh_term_freq_list_health_domain, mesh_term_freq_list_method = export_mesh_term_frequency_by_category(\n    df_mesh_term,\n    df_mesh_term_freq,\n    mesh_names_health_domain,\n    mesh_names_method,\n    directory=directory\n)\nprint(f\"Exported {len(mesh_term_freq_list_health_domain)} health domain entries\")\nprint(f\"Exported {len(mesh_term_freq_list_method)} method entries\")",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exported 109 health domain entries\n",
      "Exported 424 method entries\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "cell_type": "code",
   "id": "9c1649bc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-22T21:27:06.210123Z",
     "start_time": "2026-01-22T21:27:06.193749Z"
    }
   },
   "source": "# Step 7: Build frequency-weighted term strings for TF-IDF\ndict_researcher_mesh_health_domain = build_researcher_mesh_string(mesh_term_freq_list_health_domain)\ndict_researcher_mesh_method = build_researcher_mesh_string(mesh_term_freq_list_method)",
   "outputs": [],
   "execution_count": 21
  },
  {
   "cell_type": "code",
   "id": "753edd5b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-22T21:27:06.545840Z",
     "start_time": "2026-01-22T21:27:06.259445Z"
    }
   },
   "source": "# Step 8: Compute TF-IDF scores\ndf_person = df_mesh_term[['First Name', 'Last Name', 'Person ID']].drop_duplicates()\n\nprint(\"Computing TF-IDF for Health Domain terms...\")\nrun_mesh_tfidf(\n    dict_researcher_mesh=dict_researcher_mesh_health_domain,\n    df_person=df_person,\n    directory=directory,\n    postfix=\"HealthDomain\"\n)\n\nprint(\"Computing TF-IDF for Method terms...\")\nrun_mesh_tfidf(\n    dict_researcher_mesh=dict_researcher_mesh_method,\n    df_person=df_person,\n    directory=directory,\n    postfix=\"Method\"\n)",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing TF-IDF for Health Domain terms...\n",
      "Computing TF-IDF for Method terms...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "                       mesh_term  tfidf_score          name\n",
       "0        3' untranslated regions     0.003219  Chunhua Weng\n",
       "1       abstracting and indexing     0.003219  Chunhua Weng\n",
       "2       academic medical centers     0.008047  Chunhua Weng\n",
       "3          access to information     0.003219  Chunhua Weng\n",
       "4                     adolescent     0.014484  Chunhua Weng\n",
       "..                           ...          ...           ...\n",
       "419  wearable electronic devices     0.003219  Chunhua Weng\n",
       "420                  web browser     0.003219  Chunhua Weng\n",
       "421                     workflow     0.004828  Chunhua Weng\n",
       "422                      writing     0.009656  Chunhua Weng\n",
       "423                  young adult     0.017703  Chunhua Weng\n",
       "\n",
       "[424 rows x 3 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mesh_term</th>\n",
       "      <th>tfidf_score</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3' untranslated regions</td>\n",
       "      <td>0.003219</td>\n",
       "      <td>Chunhua Weng</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>abstracting and indexing</td>\n",
       "      <td>0.003219</td>\n",
       "      <td>Chunhua Weng</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>academic medical centers</td>\n",
       "      <td>0.008047</td>\n",
       "      <td>Chunhua Weng</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>access to information</td>\n",
       "      <td>0.003219</td>\n",
       "      <td>Chunhua Weng</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>adolescent</td>\n",
       "      <td>0.014484</td>\n",
       "      <td>Chunhua Weng</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>419</th>\n",
       "      <td>wearable electronic devices</td>\n",
       "      <td>0.003219</td>\n",
       "      <td>Chunhua Weng</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>420</th>\n",
       "      <td>web browser</td>\n",
       "      <td>0.003219</td>\n",
       "      <td>Chunhua Weng</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>421</th>\n",
       "      <td>workflow</td>\n",
       "      <td>0.004828</td>\n",
       "      <td>Chunhua Weng</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>422</th>\n",
       "      <td>writing</td>\n",
       "      <td>0.009656</td>\n",
       "      <td>Chunhua Weng</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>423</th>\n",
       "      <td>young adult</td>\n",
       "      <td>0.017703</td>\n",
       "      <td>Chunhua Weng</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>424 rows × 3 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 22
  },
  {
   "cell_type": "code",
   "id": "a1d90f2f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-22T21:27:12.656214Z",
     "start_time": "2026-01-22T21:27:06.590506Z"
    }
   },
   "source": "# Step 9: Generate research focus summaries using GPT-4\nprint(\"Generating Method summaries...\")\ndict_terms_method, dict_focus_method = generate_research_focus_summaries(\n    postfix=\"Method\",\n    directory=directory,\n    generate_gpt4_response=generate_gpt4_response,\n    df_person=df_person\n)\n\nprint(\"\\nGenerating Health Domain summaries...\")\ndict_terms_hd, dict_focus_hd = generate_research_focus_summaries(\n    postfix=\"HealthDomain\",\n    directory=directory,\n    generate_gpt4_response=generate_gpt4_response,\n    df_person=df_person\n)",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating Method summaries...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:03<00:00,  3.55s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating Health Domain summaries...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:02<00:00,  2.44s/it]\n"
     ]
    }
   ],
   "execution_count": 23
  },
  {
   "cell_type": "code",
   "id": "45d37c6f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-22T21:27:13.114254Z",
     "start_time": "2026-01-22T21:27:13.025188Z"
    }
   },
   "source": "# Step 10: Combine summaries and export final results\ndf_summary = combine_research_focus_summaries(\n    directory=directory,\n    postfix_hd=\"HealthDomain\",\n    postfix_m=\"Method\",\n    output_excel=\"Research_summary_byMesh.xlsx\"\n)\n\nprint(f\"Generated profiles for {len(df_summary)} researchers\")\nprint(f\"Output saved to: {directory}/Research_summary_byMesh.xlsx\")\ndf_summary",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}