{
 "cells": [
  {
   "cell_type": "code",
   "id": "7f8466d4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-20T22:39:30.846902Z",
     "start_time": "2025-11-20T22:39:30.836658Z"
    }
   },
   "source": [
    "import json\n",
    "from collections import Counter, defaultdict \n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import ast\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import sys\n",
    "import os\n",
    "import openai\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "from kneed import KneeLocator\n",
    "\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": 325
  },
  {
   "cell_type": "code",
   "id": "20ccfdeb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-20T22:39:30.854534Z",
     "start_time": "2025-11-20T22:39:30.852613Z"
    }
   },
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ],
   "outputs": [],
   "execution_count": 326
  },
  {
   "cell_type": "code",
   "id": "3f31ecff",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-20T22:39:30.860573Z",
     "start_time": "2025-11-20T22:39:30.858679Z"
    }
   },
   "source": "openai_api_key = '' #enter your API key",
   "outputs": [],
   "execution_count": 327
  },
  {
   "cell_type": "code",
   "id": "7bbc3617",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-20T22:39:30.868691Z",
     "start_time": "2025-11-20T22:39:30.864557Z"
    }
   },
   "source": [
    "\n",
    "def load_mesh_trees(meshtree_file):\n",
    "    \"\"\"\n",
    "    Load a MeSH tree file and build ID-to-name and name-to-ID mappings.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    meshtree_file : str\n",
    "        Path to the MeSH tree file (e.g., \"mtrees2024.bin\").\n",
    "        Each line in the file is expected to be formatted as:\n",
    "            <term>;<tree_id>\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    mesh_id2name : dict\n",
    "        Dictionary mapping MeSH tree IDs (e.g., \"A01.111\") to term names.\n",
    "    \n",
    "    mesh_name2id : dict of lists\n",
    "        Dictionary mapping MeSH term names to a list of associated MeSH IDs.\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    The function also injects two additional MeSH-like IDs:\n",
    "        NEWID1 → Female  \n",
    "        NEWID2 → Male\n",
    "    \"\"\"\n",
    "    mesh_id2name = {}\n",
    "    mesh_name2id = defaultdict(list)\n",
    "\n",
    "\n",
    "    with open(meshtree_file, \"r\") as ftree:\n",
    "        for line in ftree:\n",
    "            term, tree_id = line.strip().split(\";\")\n",
    "\n",
    "            mesh_id2name[tree_id] = term\n",
    "            mesh_name2id[term].append(tree_id)\n",
    "\n",
    "    # Add the two extra synthetic entries\n",
    "    extra_entries = {\n",
    "        'NEWID1': 'Female',\n",
    "        'NEWID2': 'Male'\n",
    "    }\n",
    "\n",
    "    for mid, term in extra_entries.items():\n",
    "        mesh_id2name[mid] = term\n",
    "        mesh_name2id[term] = [mid]\n",
    "\n",
    "    return mesh_id2name, mesh_name2id\n"
   ],
   "outputs": [],
   "execution_count": 328
  },
  {
   "cell_type": "code",
   "id": "27b3b94d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-20T22:39:30.877706Z",
     "start_time": "2025-11-20T22:39:30.872319Z"
    }
   },
   "source": [
    "def process_mesh_terms(csv_file, mesh_id2name, mesh_name2id):\n",
    "    \"\"\"\n",
    "    Process researcher MeSH terms into hierarchical MeSH ancestor codes.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    csv_file : str\n",
    "        Path to the CSV file containing researcher MeSH terms.\n",
    "        Expected columns:\n",
    "            - First Name\n",
    "            - Last Name\n",
    "            - PMID\n",
    "            - Person ID\n",
    "            - mesh_term   (format: \"Term / Subheading\" or just \"Term\")\n",
    "\n",
    "    mesh_id2name : dict\n",
    "        Mapping from MeSH ID → MeSH term name.\n",
    "        Example: {\"A01.111\": \"Heart\"}.\n",
    "\n",
    "    mesh_name2id : dict or defaultdict(list)\n",
    "        Mapping from MeSH term name → list of associated MeSH IDs.\n",
    "        Example: {\"Heart\": [\"A01.111\", \"A01.112\"]}.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    df_mesh_term : pandas.DataFrame\n",
    "        A cleaned dataframe with one row per:\n",
    "            (author × PMID × ancestor MeSH term)\n",
    "        Columns:\n",
    "            First Name, Last Name, PMID,\n",
    "            Person ID, ancestor_mesh_term\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    • Handles MeSH terms with and without subheadings.\n",
    "    • Automatically assigns:\n",
    "          Female → NEWID1\n",
    "          Male   → NEWID2\n",
    "    • Builds full hierarchical ancestor chains for every MeSH ID.\n",
    "    \"\"\"\n",
    "\n",
    "    # --------------------------------------------------\n",
    "    # Helper function: split mesh term into main + subheadings\n",
    "    # --------------------------------------------------\n",
    "    def split_mesh_term(mesh_term):\n",
    "        parts = mesh_term.split(\" / \")\n",
    "        if len(parts) > 1:\n",
    "            return parts[0], parts[1:]\n",
    "        return parts[0], []\n",
    "\n",
    "    # --------------------------------------------------\n",
    "    # Helper function: recursively find ancestors\n",
    "    # --------------------------------------------------\n",
    "    def find_mesh_term_ancestors(tid, ancestor_ids):\n",
    "        ancestors = []\n",
    "        mesh_name = mesh_id2name[tid]\n",
    "\n",
    "        # Add current term\n",
    "        ancestors.append(mesh_name)\n",
    "\n",
    "        # Get all IDs associated with the same MeSH term\n",
    "        ids_for_name = mesh_name2id[mesh_name]\n",
    "        ancestor_ids += ids_for_name\n",
    "\n",
    "        # Parent IDs = chop off last part of MeSH tree number\n",
    "        parent_ids = [\".\".join(mid.split(\".\")[:-1]) for mid in ids_for_name]\n",
    "\n",
    "        for pid in parent_ids:\n",
    "            if pid and pid not in ancestor_ids:\n",
    "                new_ancestors, ancestor_ids = find_mesh_term_ancestors(pid, ancestor_ids)\n",
    "                ancestors.extend(new_ancestors)\n",
    "                ancestors = list(set(ancestors))  # unique\n",
    "        return ancestors, ancestor_ids\n",
    "\n",
    "    # --------------------------------------------------\n",
    "    # Get only ancestor names\n",
    "    # --------------------------------------------------\n",
    "    def create_mesh_term_hierarchical_codes(tid):\n",
    "        ancestors, _ = find_mesh_term_ancestors(tid, [])\n",
    "        return ancestors\n",
    "\n",
    "    # --------------------------------------------------\n",
    "    # Load CSV\n",
    "    # --------------------------------------------------\n",
    "    df_mesh = pd.read_csv(csv_file)\n",
    "\n",
    "    # Split \"Term / Subheading\"\n",
    "    df_mesh['mesh_term_only'], df_mesh['mesh_subheading'] = zip(\n",
    "        *df_mesh['MeSH Term'].apply(split_mesh_term)\n",
    "    )\n",
    "\n",
    "    # Map main term → ID(s)\n",
    "    df_mesh['mesh_term_only_id'] = df_mesh['mesh_term_only'].apply(lambda x: mesh_name2id[x])\n",
    "\n",
    "    # Assign new synthetic IDs for Female / Male\n",
    "    df_mesh.loc[df_mesh['mesh_term_only'] == 'Female', 'mesh_term_only_id'] = 'NEWID1'\n",
    "    df_mesh.loc[df_mesh['mesh_term_only'] == 'Male',   'mesh_term_only_id'] = 'NEWID2'\n",
    "\n",
    "    # Expand list of IDs to one per row\n",
    "    df_mesh = df_mesh.explode(\"mesh_term_only_id\")\n",
    "\n",
    "    # Increase recursion depth (important)\n",
    "    sys.setrecursionlimit(5000)\n",
    "\n",
    "    # Compute full MeSH ancestor hierarchy\n",
    "    df_mesh['ancestor_mesh_term'] = df_mesh['mesh_term_only_id'].apply(\n",
    "        create_mesh_term_hierarchical_codes\n",
    "    )\n",
    "\n",
    "    # Expand ancestors to one per row\n",
    "    df_mesh = df_mesh.explode('ancestor_mesh_term')\n",
    "\n",
    "    # Select final output columns\n",
    "    df_mesh = df_mesh[\n",
    "        ['First Name', 'Last Name', 'PMID',\n",
    "         'Person ID', 'ancestor_mesh_term']\n",
    "    ]\n",
    "\n",
    "    # Remove duplicates\n",
    "    df_mesh.drop_duplicates(inplace=True)\n",
    "\n",
    "    return df_mesh\n"
   ],
   "outputs": [],
   "execution_count": 329
  },
  {
   "cell_type": "code",
   "id": "03b9a0cb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-20T22:39:30.883972Z",
     "start_time": "2025-11-20T22:39:30.881570Z"
    }
   },
   "source": [
    "\n",
    "def filter_low_frequency_mesh_terms(df_mesh_term, min_frequency=2):\n",
    "    \"\"\"\n",
    "    Filter out MeSH ancestor terms that occur less than a specified frequency\n",
    "    for each researcher.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df_mesh_term : pandas.DataFrame\n",
    "        DataFrame containing at least:\n",
    "            - Person ID\n",
    "            - ancestor_mesh_term\n",
    "\n",
    "    min_frequency : int, optional (default = 2)\n",
    "        Minimum number of occurrences required for a researcher to keep a term.\n",
    "        Terms occurring fewer times than this per Person ID are removed.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    df_filtered : pandas.DataFrame\n",
    "        DataFrame with columns:\n",
    "            Person ID, ancestor_mesh_term, count\n",
    "        containing only the MeSH terms that meet the frequency threshold.\n",
    "    \"\"\"\n",
    "\n",
    "    # Compute frequency of each ancestor term per researcher\n",
    "    df_freq = (\n",
    "        df_mesh_term\n",
    "        .groupby('Person ID')['ancestor_mesh_term']\n",
    "        .value_counts()\n",
    "        .rename('count')\n",
    "        .reset_index()\n",
    "    )\n",
    "\n",
    "    # Keep terms at or above frequency threshold\n",
    "    df_filtered = df_freq[df_freq['count'] >= min_frequency]\n",
    "\n",
    "    return df_filtered\n"
   ],
   "outputs": [],
   "execution_count": 330
  },
  {
   "cell_type": "code",
   "id": "37419a45",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-20T22:39:30.892064Z",
     "start_time": "2025-11-20T22:39:30.888363Z"
    }
   },
   "source": [
    "\n",
    "def categorize_mesh_terms(\n",
    "    df_mesh_term_freq,\n",
    "    mesh_id2name,\n",
    "    mesh_name2id,\n",
    "    class_file=\"level01_mesh_selected_class_0702_2100.xlsx\"\n",
    "):\n",
    "    \"\"\"\n",
    "    Categorize MeSH ancestor terms into 'Health Domain' (H) and 'Method' (M)\n",
    "    classes using a manually tagged level-01 class file, then propagate\n",
    "    categories to child terms based on MeSH parent–child relationships.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df_mesh_term_freq : pandas.DataFrame\n",
    "        Output of filter_low_frequency_mesh_terms(), must contain:\n",
    "            - ancestor_mesh_term\n",
    "\n",
    "    mesh_id2name : dict\n",
    "        Mapping MeSH ID -> MeSH term name\n",
    "\n",
    "    mesh_name2id : dict or defaultdict(list)\n",
    "        Mapping MeSH term name -> list of MeSH IDs\n",
    "\n",
    "    class_file : str\n",
    "        Excel file mapping MeSH terms to top-level class labels.\n",
    "        Must contain:\n",
    "            - 'name'  (MeSH term)\n",
    "            - 'Class' ('H' or 'M')\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    mesh_names_health_domain : list\n",
    "        All MeSH term names categorized under Health Domain (H)\n",
    "\n",
    "    mesh_names_method : list\n",
    "        All MeSH term names categorized under Methods (M)\n",
    "    \"\"\"\n",
    "\n",
    "    # ------------------------------\n",
    "    # Load class definitions\n",
    "    # ------------------------------\n",
    "    df_class = pd.read_excel(class_file, index_col=0)\n",
    "\n",
    "    mesh_names_health_domain_manual = list(df_class[df_class['Class'] == 'H']['name'])\n",
    "    mesh_names_method_manual = list(df_class[df_class['Class'] == 'M']['name'])\n",
    "\n",
    "    # -------------------------------------------\n",
    "    # Get all unique ancestor terms from freq df\n",
    "    # -------------------------------------------\n",
    "    df_temp = df_mesh_term_freq[['ancestor_mesh_term']].drop_duplicates()\n",
    "\n",
    "    # Map term → IDs\n",
    "    df_temp['term_id'] = df_temp['ancestor_mesh_term'].apply(lambda x: mesh_name2id[x])\n",
    "    df_temp = df_temp.explode('term_id')\n",
    "\n",
    "    # Sort IDs by length so parents come first\n",
    "    df_temp['length'] = df_temp['term_id'].apply(len)\n",
    "    df_temp = df_temp.sort_values(by='length').drop_duplicates()\n",
    "\n",
    "    term_ids = list(df_temp['term_id'])\n",
    "\n",
    "    # -------------------------------------------\n",
    "    # Initialize category lists\n",
    "    # -------------------------------------------\n",
    "    mesh_names_health_domain = mesh_names_health_domain_manual.copy()\n",
    "    mesh_names_method = mesh_names_method_manual.copy()\n",
    "\n",
    "    # -------------------------------------------\n",
    "    # Categorize by tracing parent IDs\n",
    "    # -------------------------------------------\n",
    "    for tid in term_ids:\n",
    "        term_name = mesh_id2name[tid]\n",
    "\n",
    "        # Skip terms already categorized manually\n",
    "        if (term_name in mesh_names_health_domain_manual) or (term_name in mesh_names_method):\n",
    "            continue\n",
    "\n",
    "        parts = tid.split(\".\")\n",
    "        if len(parts) >= 2:\n",
    "            parent_id = \".\".join(parts[:-1])\n",
    "            parent_name = mesh_id2name[parent_id]\n",
    "\n",
    "            # Inherit health domain from parent\n",
    "            if parent_name in mesh_names_health_domain:\n",
    "                mesh_names_health_domain.append(term_name)\n",
    "\n",
    "            # Inherit method class from parent\n",
    "            if parent_name in mesh_names_method:\n",
    "                mesh_names_method.append(term_name)\n",
    "\n",
    "    # Remove duplicates\n",
    "    mesh_names_health_domain = list(set(mesh_names_health_domain))\n",
    "    mesh_names_method = list(set(mesh_names_method))\n",
    "\n",
    "    return mesh_names_health_domain, mesh_names_method\n"
   ],
   "outputs": [],
   "execution_count": 331
  },
  {
   "cell_type": "code",
   "id": "56f1f0b8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-20T22:39:30.897780Z",
     "start_time": "2025-11-20T22:39:30.895040Z"
    }
   },
   "source": [
    "def remove_meaningless_mesh_terms(df_mesh_term_freq, mesh_id2name):\n",
    "    \"\"\"\n",
    "    Remove meaningless or overly broad MeSH ancestor terms from the\n",
    "    df_mesh_term_freq DataFrame.\n",
    "\n",
    "    This function filters out:\n",
    "        • a predefined list of non-informative MeSH terms\n",
    "        • any MeSH terms whose MeSH ID begins with 'Z01' (automatically added)\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df_mesh_term_freq : pandas.DataFrame\n",
    "        DataFrame containing at least:\n",
    "            - ancestor_mesh_term\n",
    "\n",
    "    mesh_id2name : dict\n",
    "        Mapping from MeSH ID → MeSH term name\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    df_filtered : pandas.DataFrame\n",
    "        DataFrame with meaningless ancestor terms removed.\n",
    "    \"\"\"\n",
    "\n",
    "    # Base list of meaningless or overly broad MeSH terms\n",
    "    meaningless_mesh = [\n",
    "        'Eukaryota', 'Animals', 'Chordata', 'Vertebrates', 'Mammals', 'Eutheria',\n",
    "        'Primates', 'Haplorhini', 'Catarrhini', 'Hominidae', 'Humans',\n",
    "        'Natural Science Disciplines', 'Science', 'Research', 'Methods',\n",
    "        'Investigative Techniques', 'Persons', 'Health Occupations',\n",
    "        'Equipment and Supplies', 'Electrical Equipment and Supplies',\n",
    "        'Biomedical Research', 'Household Products', 'Photography',\n",
    "        'Financial Management', 'life', 'Medicine', 'Diseases'\n",
    "    ]\n",
    "\n",
    "    # Add all terms whose MeSH ID starts with Z01\n",
    "    for mid, name in mesh_id2name.items():\n",
    "        if mid.startswith('Z01'):\n",
    "            meaningless_mesh.append(name)\n",
    "\n",
    "    # Filter out all meaningless terms\n",
    "    df_filtered = df_mesh_term_freq[\n",
    "        ~df_mesh_term_freq['ancestor_mesh_term'].isin(meaningless_mesh)\n",
    "    ].copy()\n",
    "\n",
    "    return df_filtered\n"
   ],
   "outputs": [],
   "execution_count": 332
  },
  {
   "cell_type": "code",
   "id": "62dddd0f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-20T22:39:30.903489Z",
     "start_time": "2025-11-20T22:39:30.900923Z"
    }
   },
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "def export_mesh_term_frequency_by_category(\n",
    "        df_mesh,\n",
    "        df_mesh_term_freq,\n",
    "        mesh_names_health_domain,\n",
    "        mesh_names_method,\n",
    "        directory\n",
    "    ):\n",
    "    \"\"\"\n",
    "    Export MeSH term frequency tables for Health Domain and Method categories,\n",
    "    merging researcher information and saving results to Excel files.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df_mesh : pandas.DataFrame\n",
    "        Must contain:\n",
    "            - First Name\n",
    "            - Last Name\n",
    "            - Person ID\n",
    "\n",
    "    df_mesh_term_freq : pandas.DataFrame\n",
    "        Must contain:\n",
    "            - Person ID\n",
    "            - ancestor_mesh_term\n",
    "            - count\n",
    "\n",
    "    mesh_names_health_domain : list\n",
    "        List of MeSH terms classified as Health Domain.\n",
    "\n",
    "    mesh_names_method : list\n",
    "        List of MeSH terms classified as Methods.\n",
    "\n",
    "    directory : str\n",
    "        Folder where Excel files will be saved.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    mesh_term_freq_list_health_domain : list of lists\n",
    "        Health domain term frequencies with researcher names included.\n",
    "\n",
    "    mesh_term_freq_list_method : list of lists\n",
    "        Method term frequencies with researcher names included.\n",
    "    \"\"\"\n",
    "\n",
    "    # --------------------------\n",
    "    # Unique researcher info\n",
    "    # --------------------------\n",
    "    df_person = df_mesh[['First Name', 'Last Name', 'Person ID']].drop_duplicates()\n",
    "\n",
    "    # --------------------------\n",
    "    # Filter categories\n",
    "    # --------------------------\n",
    "    df_health = df_mesh_term_freq[\n",
    "        df_mesh_term_freq['ancestor_mesh_term'].isin(mesh_names_health_domain)\n",
    "    ].merge(df_person, on='Person ID')\n",
    "\n",
    "    df_method = df_mesh_term_freq[\n",
    "        df_mesh_term_freq['ancestor_mesh_term'].isin(mesh_names_method)\n",
    "    ].merge(df_person, on='Person ID')\n",
    "\n",
    "    # --------------------------\n",
    "    # Save Excel files\n",
    "    # --------------------------\n",
    "    os.makedirs(directory, exist_ok=True)\n",
    "\n",
    "    df_health.to_excel(\n",
    "        os.path.join(directory, \"mesh_term_freq_per_faculty_HealthDomain.xlsx\"),\n",
    "        index=False\n",
    "    )\n",
    "    df_method.to_excel(\n",
    "        os.path.join(directory, \"mesh_term_freq_per_faculty_Method.xlsx\"),\n",
    "        index=False\n",
    "    )\n",
    "\n",
    "    # --------------------------\n",
    "    # Convert to list format\n",
    "    # --------------------------\n",
    "    mesh_term_freq_list_health_domain = df_health.values.tolist()\n",
    "    mesh_term_freq_list_method = df_method.values.tolist()\n",
    "\n",
    "    return mesh_term_freq_list_health_domain, mesh_term_freq_list_method\n"
   ],
   "outputs": [],
   "execution_count": 333
  },
  {
   "cell_type": "code",
   "id": "bdf142d6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-20T22:39:30.908367Z",
     "start_time": "2025-11-20T22:39:30.906337Z"
    }
   },
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def build_researcher_mesh_string(mesh_term_freq_list):\n",
    "    \"\"\"\n",
    "    Build a dictionary mapping Person ID → semicolon-separated MeSH terms,\n",
    "    where each term is repeated according to its frequency.\n",
    "\n",
    "    Accepts rows that contain more than three columns, such as:\n",
    "        [Person ID, term, freq, First Name, Last Name]\n",
    "\n",
    "    Only the first three fields are used:\n",
    "        Person ID, term, freq\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    mesh_term_freq_list : list of lists\n",
    "        Each row must start with:\n",
    "            [Person ID, term, freq, ...]\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dict_researcher_mesh : dict\n",
    "        Mapping:\n",
    "            Person ID → \"term;term;term2;term2;...\"\n",
    "    \"\"\"\n",
    "\n",
    "    dict_researcher_mesh = defaultdict(str)\n",
    "\n",
    "    for row in mesh_term_freq_list:\n",
    "        # Safely unpack only the first three values\n",
    "        person_id, term, freq = row[:3]\n",
    "\n",
    "        # Repeat term freq times and append\n",
    "        dict_researcher_mesh[person_id] += (term + \";\") * int(freq)\n",
    "\n",
    "    # Remove trailing semicolon from each entry\n",
    "    dict_researcher_mesh = {\n",
    "        pid: terms.rstrip(\";\")\n",
    "        for pid, terms in dict_researcher_mesh.items()\n",
    "    }\n",
    "\n",
    "    return dict_researcher_mesh\n"
   ],
   "outputs": [],
   "execution_count": 334
  },
  {
   "cell_type": "code",
   "id": "725ddab8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-20T22:39:30.914981Z",
     "start_time": "2025-11-20T22:39:30.911300Z"
    }
   },
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "def run_mesh_tfidf(\n",
    "        dict_researcher_mesh,\n",
    "        df_person,\n",
    "        directory,\n",
    "        postfix=\"HealthDomain\"\n",
    "    ):\n",
    "    \"\"\"\n",
    "    Compute TF-IDF for researcher MeSH term profiles.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    dict_researcher_mesh : dict\n",
    "        Mapping: Person ID -> \"term1;term1;term2;term3;...\"\n",
    "        (Repeated terms represent frequencies)\n",
    "\n",
    "    df_person : pandas.DataFrame\n",
    "        Contains researcher identity columns:\n",
    "            - Person ID\n",
    "            - First Name\n",
    "            - Last Name\n",
    "\n",
    "    directory : str\n",
    "        Output folder where CSV/Excel files will be saved.\n",
    "\n",
    "    postfix : str\n",
    "        Labels output files, e.g., \"HealthDomain\" or \"Method\".\n",
    "\n",
    "\n",
    "\n",
    "    Outputs (saved to disk)\n",
    "    -----------------------\n",
    "    1. term_per_researcher_tfidf_{postfix}.csv\n",
    "\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    df_terms_tfidf : pandas.DataFrame\n",
    "        TF-IDF table (long format, term × faculty)\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # ---------------------------------------------------------\n",
    "    # Tokenizer (split text by semicolon)\n",
    "    # ---------------------------------------------------------\n",
    "    def custom_tokenizer(text):\n",
    "        return [token.strip() for token in text.split(';') if token.strip()]\n",
    "\n",
    "    # ---------------------------------------------------------\n",
    "    # Build corpus and faculty IDs\n",
    "    # ---------------------------------------------------------\n",
    "    corpus = list(dict_researcher_mesh.values())\n",
    "    faculty_ids = list(dict_researcher_mesh.keys())\n",
    "\n",
    "    # ---------------------------------------------------------\n",
    "    # TF-IDF vectorizer\n",
    "    # ---------------------------------------------------------\n",
    "    vectorizer = TfidfVectorizer(tokenizer=custom_tokenizer)\n",
    "    X = vectorizer.fit_transform(corpus)\n",
    "\n",
    "    # ---------------------------------------------------------\n",
    "    # Build TF-IDF dataframe: long format (term, faculty, score)\n",
    "    # ---------------------------------------------------------\n",
    "    df_terms_tfidf = pd.DataFrame(X.toarray())\n",
    "    df_terms_tfidf[\"Person ID\"] = faculty_ids\n",
    "    df_terms_tfidf.set_index(\"Person ID\", inplace=True)\n",
    "\n",
    "    df_terms_tfidf = df_terms_tfidf.T\n",
    "    df_terms_tfidf[\"mesh_term\"] = vectorizer.get_feature_names_out()\n",
    "    df_terms_tfidf.set_index(\"mesh_term\", inplace=True)\n",
    "\n",
    "    df_terms_tfidf = pd.DataFrame(df_terms_tfidf.unstack())\n",
    "    df_terms_tfidf.reset_index(inplace=True)\n",
    "\n",
    "    df_terms_tfidf.rename(columns={\n",
    "        \"level_0\": \"Person ID\",\n",
    "        0: \"tfidf_score\"\n",
    "    }, inplace=True)\n",
    "\n",
    "    # Add researcher names\n",
    "    df_terms_tfidf = df_terms_tfidf.merge(df_person, on=\"Person ID\")\n",
    "    df_terms_tfidf[\"name\"] = df_terms_tfidf[\"First Name\"] + \" \" + df_terms_tfidf[\"Last Name\"]\n",
    "    df_terms_tfidf.drop([\"Person ID\", \"First Name\", \"Last Name\"], axis=1, inplace=True)\n",
    "\n",
    "    # Save TF-IDF table\n",
    "    os.makedirs(directory, exist_ok=True)\n",
    "    df_terms_tfidf.to_csv(os.path.join(directory, f\"term_per_researcher_tfidf_{postfix}.csv\"), index=False)\n",
    "\n",
    "    \n",
    "    return df_terms_tfidf\n"
   ],
   "outputs": [],
   "execution_count": 335
  },
  {
   "cell_type": "code",
   "id": "cb294150",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-20T22:39:30.930346Z",
     "start_time": "2025-11-20T22:39:30.917656Z"
    }
   },
   "source": [
    "from openai import OpenAI\n",
    "import os\n",
    "client = OpenAI(api_key = openai_api_key)\n",
    "def generate_gpt4_response(content, print_output=False):\n",
    "    try:\n",
    "        completions = client.chat.completions.create( #a method that allows you to generate text-based chatbot responses using a pre-trained GPT language model.\n",
    "            model=\"gpt-4o\", \n",
    "            top_p = 0.1,\n",
    "            temperature = 0, #controls the level of randomness or creativity in the generated text; . A higher temperature value will result in a more diverse and creative output, as it increases the probability of sampling lower probability tokens. \n",
    "    #         max_tokens = 2000, #controls the maximum number of tokens (words or subwords) in the generated text.\n",
    "    #         stop = ['###'], #specifies a sequence of tokens that the GPT model should stop generating text when it encounters\n",
    "            n = 1, #the number of possible chat completions or responses that the GPT model should generate in response to a given prompt\n",
    "            messages=[\n",
    "                {'role':'system', 'content': 'You are a dean of a college.'},\n",
    "              {'role':'user', 'content': content},\n",
    "              ])\n",
    "\n",
    "        # Displaying the output can be helpful if things go wrong\n",
    "        if print_output:\n",
    "            print(completions)\n",
    "\n",
    "        # Return the first choice's text\n",
    "        return completions.choices[0].message.content\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        return None\n"
   ],
   "outputs": [],
   "execution_count": 336
  },
  {
   "cell_type": "code",
   "id": "6abdf015",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-20T22:39:30.937871Z",
     "start_time": "2025-11-20T22:39:30.933316Z"
    }
   },
   "source": [
    "def generate_research_focus_summaries(\n",
    "        postfix,\n",
    "        directory,\n",
    "        generate_gpt4_response,\n",
    "        df_person,\n",
    "        elbow_S=5\n",
    "    ):\n",
    "    \"\"\"\n",
    "    Generate research focus summaries for each researcher based on TF-IDF MeSH terms.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    postfix : str\n",
    "        \"Method\" or \"HealthDomain\"\n",
    "        Determines:\n",
    "            - which TF-IDF file to load\n",
    "            - how the summary sentence is phrased\n",
    "\n",
    "    directory : str\n",
    "        Folder where input files are located and output pickles will be saved.\n",
    "\n",
    "    generate_gpt4_response : function\n",
    "        A function that sends a prompt to GPT-4 and returns the response text.\n",
    "        Must return None on failure, so the retry loop can handle errors.\n",
    "\n",
    "    df_person : pandas.DataFrame\n",
    "        Must contain:\n",
    "            - Person ID\n",
    "            - First Name\n",
    "            - Last Name\n",
    "\n",
    "    elbow_S : int\n",
    "        Sensitivity parameter for KneeLocator.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dict_terms_for_a_researcher_for_focus : dict\n",
    "        researcher_name -> semicolon-separated selected MeSH terms\n",
    "\n",
    "    dict_research_focus_for_a_researcher : dict\n",
    "        researcher_name -> GPT summary sentence\n",
    "    \"\"\"\n",
    "\n",
    "    # -----------------------------------------\n",
    "    # Load TF-IDF file\n",
    "    # -----------------------------------------\n",
    "    file_path = os.path.join(directory, f\"term_per_researcher_tfidf_{postfix}.csv\")\n",
    "    df_terms_tfidf = pd.read_csv(file_path)\n",
    "\n",
    "    # Keep only positive-scored terms\n",
    "    df_terms_tfidf = df_terms_tfidf[df_terms_tfidf[\"tfidf_score\"] > 0]\n",
    "    print(df_terms_tfidf)\n",
    "    # Build dict: researcher_name -> {term: score}\n",
    "    dict_mesh_term_tfidf = (\n",
    "        df_terms_tfidf.groupby(\"name\")\n",
    "        .apply(lambda x: dict(zip(x[\"mesh_term\"], x[\"tfidf_score\"])))\n",
    "        .to_dict()\n",
    "    )\n",
    "\n",
    "    # List of researcher names\n",
    "    name_list = list(dict_mesh_term_tfidf.keys())\n",
    "\n",
    "    dict_terms_for_a_researcher_for_focus = {}\n",
    "    dict_research_focus_for_a_researcher = {}\n",
    "\n",
    "    # -----------------------------------------\n",
    "    # Process each researcher\n",
    "    # -----------------------------------------\n",
    "    for m in tqdm(name_list):\n",
    "        df_temp = df_terms_tfidf[df_terms_tfidf[\"name\"] == m].copy()\n",
    "        df_temp.sort_values(\"tfidf_score\", inplace=True, ascending=False)\n",
    "\n",
    "        df_temp[\"id_for_elbow_point\"] = np.arange(len(df_temp))\n",
    "\n",
    "        # Use KneeLocator to find elbow\n",
    "        kneedle = KneeLocator(\n",
    "            df_temp[\"id_for_elbow_point\"],\n",
    "            df_temp[\"tfidf_score\"],\n",
    "            S=elbow_S,\n",
    "            curve=\"convex\",\n",
    "            direction=\"decreasing\"\n",
    "        )\n",
    "\n",
    "        if kneedle.knee is None:\n",
    "            # If elbow fails, fallback to top 5% or at least 3 terms\n",
    "            knee_point = max(3, int(0.05 * len(df_temp)))\n",
    "        else:\n",
    "            knee_point = kneedle.knee\n",
    "\n",
    "        # Select the top-knee terms\n",
    "        df_select = df_temp.iloc[:knee_point]\n",
    "        term_list = list(df_select[\"mesh_term\"])\n",
    "\n",
    "        # Store term list\n",
    "        dict_terms_for_a_researcher_for_focus[m] = \"; \".join(term_list)\n",
    "\n",
    "        # -----------------------------------------\n",
    "        # GPT-4 summarization\n",
    "        # -----------------------------------------\n",
    "        prompt = (\n",
    "            \"Help me summarize this group of phrases into 1 sentence as a research focus:\\n\"\n",
    "            + dict_terms_for_a_researcher_for_focus[m]\n",
    "            + \"\\nPlease start with: The research focus is on\"\n",
    "        )\n",
    "\n",
    "        summary = None\n",
    "        attempt = 0\n",
    "\n",
    "        while summary is None:\n",
    "            summary = generate_gpt4_response(prompt)\n",
    "            attempt += 1\n",
    "            if summary is None:\n",
    "                print(f\"[Retry {attempt}] GPT failed, sleeping...\")\n",
    "                time.sleep(3)\n",
    "\n",
    "        # Rewrite sentence prefix\n",
    "        if postfix == \"Method\":\n",
    "            summary = summary.replace(\n",
    "                \"The research focus is on\", \n",
    "                \"This researcher has mainly contributed to\"\n",
    "            )\n",
    "        else:\n",
    "            summary = summary.replace(\n",
    "                \"The research focus is on\",\n",
    "                \"This researcher mainly focused on\"\n",
    "            )\n",
    "\n",
    "        dict_research_focus_for_a_researcher[m] = summary\n",
    "\n",
    "    # -----------------------------------------\n",
    "    # Save pickle files\n",
    "    # -----------------------------------------\n",
    "    with open(os.path.join(directory, f\"dict_terms_for_a_researcher_for_focus{postfix}.pickle\"), \"wb\") as f:\n",
    "        pickle.dump(dict_terms_for_a_researcher_for_focus, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "    with open(os.path.join(directory, f\"dict_research_focus_for_a_researcher_{postfix}.pickle\"), \"wb\") as f:\n",
    "        pickle.dump(dict_research_focus_for_a_researcher, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "    return dict_terms_for_a_researcher_for_focus, dict_research_focus_for_a_researcher\n"
   ],
   "outputs": [],
   "execution_count": 337
  },
  {
   "cell_type": "code",
   "id": "d76ff275",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-20T22:39:30.943677Z",
     "start_time": "2025-11-20T22:39:30.940703Z"
    }
   },
   "source": [
    "import os\n",
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def combine_research_focus_summaries(\n",
    "        directory,\n",
    "        postfix_hd=\"HealthDomain\",\n",
    "        postfix_m=\"Method\",\n",
    "        output_excel=\"Research_summary_byMesh.xlsx\"\n",
    "    ):\n",
    "    \"\"\"\n",
    "    Combine research focus summaries from HealthDomain and Method categories\n",
    "    into a single summary per researcher.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    directory : str\n",
    "        Folder where the pickle files are located.\n",
    "\n",
    "    postfix_hd : str (default=\"HealthDomain\")\n",
    "        Postfix for the HealthDomain summary pickle file:\n",
    "        dict_research_focus_for_a_researcher_{postfix_hd}.pickle\n",
    "\n",
    "    postfix_m : str (default=\"Method\")\n",
    "        Postfix for the Method summary pickle file:\n",
    "        dict_research_focus_for_a_researcher_{postfix_m}.pickle\n",
    "\n",
    "    output_excel : str (default=\"Research_summary_byMesh.xlsx\")\n",
    "        Name of the final Excel file to save.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    df_research_summary : pandas.DataFrame\n",
    "        DataFrame with columns:\n",
    "            - Researcher_name\n",
    "            - Research_direction\n",
    "    \"\"\"\n",
    "\n",
    "    # ----------------------------\n",
    "    # Load HealthDomain summary\n",
    "    # ----------------------------\n",
    "    hd_path = os.path.join(\n",
    "        directory, f\"dict_research_focus_for_a_researcher_{postfix_hd}.pickle\"\n",
    "    )\n",
    "    with open(hd_path, \"rb\") as handle:\n",
    "        dict_hd = pickle.load(handle)\n",
    "\n",
    "    df_hd = (\n",
    "        pd.DataFrame.from_dict(dict_hd, orient=\"index\")\n",
    "        .reset_index()\n",
    "        .rename(columns={\"index\": \"Researcher_name\", 0: \"Research_summary_hd\"})\n",
    "    )\n",
    "\n",
    "    # ----------------------------\n",
    "    # Load Method summary\n",
    "    # ----------------------------\n",
    "    m_path = os.path.join(\n",
    "        directory, f\"dict_research_focus_for_a_researcher_{postfix_m}.pickle\"\n",
    "    )\n",
    "    with open(m_path, \"rb\") as handle:\n",
    "        dict_m = pickle.load(handle)\n",
    "\n",
    "    df_m = (\n",
    "        pd.DataFrame.from_dict(dict_m, orient=\"index\")\n",
    "        .reset_index()\n",
    "        .rename(columns={\"index\": \"Researcher_name\", 0: \"Research_summary_m\"})\n",
    "    )\n",
    "\n",
    "    # ----------------------------\n",
    "    # Merge both summaries\n",
    "    # ----------------------------\n",
    "    df = df_hd.merge(df_m, on=\"Researcher_name\", how=\"outer\")\n",
    "    df.fillna(\"\", inplace=True)\n",
    "\n",
    "    # ----------------------------\n",
    "    # Combine both text summaries\n",
    "    # ----------------------------\n",
    "    df[\"Research_direction\"] = (\n",
    "        df[\"Research_summary_hd\"].astype(str)\n",
    "        + \"\\n\"\n",
    "        + df[\"Research_summary_m\"].astype(str)\n",
    "    ).str.strip(\"\\n\")\n",
    "\n",
    "    df_final = df[[\"Researcher_name\", \"Research_direction\"]]\n",
    "\n",
    "    # ----------------------------\n",
    "    # Save Excel\n",
    "    # ----------------------------\n",
    "    output_path = os.path.join(directory, output_excel)\n",
    "    df_final.to_excel(output_path, index=False)\n",
    "\n",
    "    return df_final\n"
   ],
   "outputs": [],
   "execution_count": 338
  },
  {
   "cell_type": "code",
   "id": "038e0883",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-20T22:39:30.947664Z",
     "start_time": "2025-11-20T22:39:30.946360Z"
    }
   },
   "source": [
    "directory = \"results/intermediate_result\"\n",
    "\n",
    "input_file = \"data/output_sample/preprocess/filtered_publications.csv\""
   ],
   "outputs": [],
   "execution_count": 339
  },
  {
   "cell_type": "code",
   "id": "19290c23",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-20T22:39:30.994928Z",
     "start_time": "2025-11-20T22:39:30.950166Z"
    }
   },
   "source": [
    "meshtree_file = \"mtrees2024.bin\" \n",
    "mesh_id2name, mesh_name2id = load_mesh_trees(meshtree_file)\n"
   ],
   "outputs": [],
   "execution_count": 340
  },
  {
   "cell_type": "code",
   "id": "04e18282",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-20T22:39:31.063975Z",
     "start_time": "2025-11-20T22:39:31.001451Z"
    }
   },
   "source": [
    "df_mesh_term = process_mesh_terms(\n",
    "    input_file,\n",
    "    mesh_id2name,\n",
    "    mesh_name2id\n",
    ")\n",
    "\n",
    "df_mesh_term.head()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  First Name Last Name      PMID  Person ID ancestor_mesh_term\n",
       "0    Chunhua      Weng  38838949          1            Mammals\n",
       "0    Chunhua      Weng  38838949          1         Catarrhini\n",
       "0    Chunhua      Weng  38838949          1          Hominidae\n",
       "0    Chunhua      Weng  38838949          1          Eukaryota\n",
       "0    Chunhua      Weng  38838949          1           Eutheria"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>First Name</th>\n",
       "      <th>Last Name</th>\n",
       "      <th>PMID</th>\n",
       "      <th>Person ID</th>\n",
       "      <th>ancestor_mesh_term</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Chunhua</td>\n",
       "      <td>Weng</td>\n",
       "      <td>38838949</td>\n",
       "      <td>1</td>\n",
       "      <td>Mammals</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Chunhua</td>\n",
       "      <td>Weng</td>\n",
       "      <td>38838949</td>\n",
       "      <td>1</td>\n",
       "      <td>Catarrhini</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Chunhua</td>\n",
       "      <td>Weng</td>\n",
       "      <td>38838949</td>\n",
       "      <td>1</td>\n",
       "      <td>Hominidae</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Chunhua</td>\n",
       "      <td>Weng</td>\n",
       "      <td>38838949</td>\n",
       "      <td>1</td>\n",
       "      <td>Eukaryota</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Chunhua</td>\n",
       "      <td>Weng</td>\n",
       "      <td>38838949</td>\n",
       "      <td>1</td>\n",
       "      <td>Eutheria</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 341,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 341
  },
  {
   "cell_type": "code",
   "id": "c459d83f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-20T22:39:31.095823Z",
     "start_time": "2025-11-20T22:39:31.090130Z"
    }
   },
   "source": [
    "df_mesh_term_freq = filter_low_frequency_mesh_terms(df_mesh_term, min_frequency=2)\n"
   ],
   "outputs": [],
   "execution_count": 342
  },
  {
   "cell_type": "code",
   "id": "e99e0b11",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-20T22:39:31.194350Z",
     "start_time": "2025-11-20T22:39:31.127229Z"
    }
   },
   "source": [
    "mesh_names_health_domain, mesh_names_method = categorize_mesh_terms(\n",
    "    df_mesh_term_freq,\n",
    "    mesh_id2name,\n",
    "    mesh_name2id,\n",
    "    class_file=\"level01_mesh_selected_class_0702_2100.xlsx\"\n",
    ")\n",
    "\n",
    "print(len(mesh_names_health_domain), len(mesh_names_method))\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "371 1254\n"
     ]
    }
   ],
   "execution_count": 343
  },
  {
   "cell_type": "code",
   "id": "b4eb2185",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-20T22:39:31.207008Z",
     "start_time": "2025-11-20T22:39:31.199693Z"
    }
   },
   "source": [
    "df_mesh_term_freq = remove_meaningless_mesh_terms(\n",
    "    df_mesh_term_freq,\n",
    "    mesh_id2name\n",
    ")\n"
   ],
   "outputs": [],
   "execution_count": 344
  },
  {
   "cell_type": "code",
   "id": "aa3fb96e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-20T22:39:31.243354Z",
     "start_time": "2025-11-20T22:39:31.210687Z"
    }
   },
   "source": [
    "mesh_term_freq_list_health_domain, mesh_term_freq_list_method = export_mesh_term_frequency_by_category(\n",
    "    df_mesh_term,\n",
    "    df_mesh_term_freq,\n",
    "    mesh_names_health_domain,\n",
    "    mesh_names_method,\n",
    "    directory=directory\n",
    ")\n"
   ],
   "outputs": [],
   "execution_count": 345
  },
  {
   "cell_type": "code",
   "id": "9c1649bc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-20T22:39:31.253542Z",
     "start_time": "2025-11-20T22:39:31.247695Z"
    }
   },
   "source": [
    "dict_researcher_mesh_health_domain = build_researcher_mesh_string(mesh_term_freq_list_health_domain)\n",
    "dict_researcher_mesh_method = build_researcher_mesh_string(mesh_term_freq_list_method)\n"
   ],
   "outputs": [],
   "execution_count": 346
  },
  {
   "cell_type": "code",
   "id": "753edd5b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-20T22:39:31.328441Z",
     "start_time": "2025-11-20T22:39:31.257568Z"
    }
   },
   "source": [
    "df_person = df_mesh_term[['First Name', 'Last Name', 'Person ID']]\n",
    "df_person.drop_duplicates(inplace=True)\n",
    "\n",
    "run_mesh_tfidf(\n",
    "    dict_researcher_mesh=dict_researcher_mesh_health_domain,\n",
    "    df_person=df_person,\n",
    "    directory=directory,\n",
    "    postfix=\"HealthDomain\"\n",
    ")\n",
    "run_mesh_tfidf(\n",
    "    dict_researcher_mesh=dict_researcher_mesh_method,\n",
    "    df_person=df_person,\n",
    "    directory=directory,\n",
    "    postfix=\"Method\"\n",
    ")\n"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                       mesh_term  tfidf_score          name\n",
       "0        3' untranslated regions     0.003219  Chunhua Weng\n",
       "1       abstracting and indexing     0.003219  Chunhua Weng\n",
       "2       academic medical centers     0.008047  Chunhua Weng\n",
       "3          access to information     0.003219  Chunhua Weng\n",
       "4                     adolescent     0.014484  Chunhua Weng\n",
       "..                           ...          ...           ...\n",
       "419  wearable electronic devices     0.003219  Chunhua Weng\n",
       "420                  web browser     0.003219  Chunhua Weng\n",
       "421                     workflow     0.004828  Chunhua Weng\n",
       "422                      writing     0.009656  Chunhua Weng\n",
       "423                  young adult     0.017703  Chunhua Weng\n",
       "\n",
       "[424 rows x 3 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mesh_term</th>\n",
       "      <th>tfidf_score</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3' untranslated regions</td>\n",
       "      <td>0.003219</td>\n",
       "      <td>Chunhua Weng</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>abstracting and indexing</td>\n",
       "      <td>0.003219</td>\n",
       "      <td>Chunhua Weng</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>academic medical centers</td>\n",
       "      <td>0.008047</td>\n",
       "      <td>Chunhua Weng</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>access to information</td>\n",
       "      <td>0.003219</td>\n",
       "      <td>Chunhua Weng</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>adolescent</td>\n",
       "      <td>0.014484</td>\n",
       "      <td>Chunhua Weng</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>419</th>\n",
       "      <td>wearable electronic devices</td>\n",
       "      <td>0.003219</td>\n",
       "      <td>Chunhua Weng</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>420</th>\n",
       "      <td>web browser</td>\n",
       "      <td>0.003219</td>\n",
       "      <td>Chunhua Weng</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>421</th>\n",
       "      <td>workflow</td>\n",
       "      <td>0.004828</td>\n",
       "      <td>Chunhua Weng</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>422</th>\n",
       "      <td>writing</td>\n",
       "      <td>0.009656</td>\n",
       "      <td>Chunhua Weng</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>423</th>\n",
       "      <td>young adult</td>\n",
       "      <td>0.017703</td>\n",
       "      <td>Chunhua Weng</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>424 rows × 3 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 347,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 347
  },
  {
   "cell_type": "code",
   "id": "9a91bdf6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-20T22:39:31.353663Z",
     "start_time": "2025-11-20T22:39:31.352480Z"
    }
   },
   "source": [],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "a1d90f2f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-20T22:39:35.769762Z",
     "start_time": "2025-11-20T22:39:31.385840Z"
    }
   },
   "source": [
    "dict_terms_method, dict_focus_method = generate_research_focus_summaries(\n",
    "    postfix=\"Method\",\n",
    "    directory=directory,\n",
    "    generate_gpt4_response=generate_gpt4_response,\n",
    "    df_person=df_person\n",
    ")\n",
    "dict_terms_hd, dict_focus_hd = generate_research_focus_summaries(\n",
    "    postfix=\"HealthDomain\",\n",
    "    directory=directory,\n",
    "    generate_gpt4_response=generate_gpt4_response,\n",
    "    df_person=df_person\n",
    ")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       mesh_term  tfidf_score          name\n",
      "0        3' untranslated regions     0.003219  Chunhua Weng\n",
      "1       abstracting and indexing     0.003219  Chunhua Weng\n",
      "2       academic medical centers     0.008047  Chunhua Weng\n",
      "3          access to information     0.003219  Chunhua Weng\n",
      "4                     adolescent     0.014484  Chunhua Weng\n",
      "..                           ...          ...           ...\n",
      "419  wearable electronic devices     0.003219  Chunhua Weng\n",
      "420                  web browser     0.003219  Chunhua Weng\n",
      "421                     workflow     0.004828  Chunhua Weng\n",
      "422                      writing     0.009656  Chunhua Weng\n",
      "423                  young adult     0.017703  Chunhua Weng\n",
      "\n",
      "[424 rows x 3 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:03<00:00,  3.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                mesh_term  tfidf_score          name\n",
      "0       alzheimer disease     0.031428  Chunhua Weng\n",
      "1                attitude     0.054999  Chunhua Weng\n",
      "2      attitude to health     0.047142  Chunhua Weng\n",
      "3     autoimmune diseases     0.015714  Chunhua Weng\n",
      "4    bacterial infections     0.015714  Chunhua Weng\n",
      "..                    ...          ...           ...\n",
      "107     urogenital system     0.031428  Chunhua Weng\n",
      "108     urologic diseases     0.031428  Chunhua Weng\n",
      "109     vascular diseases     0.031428  Chunhua Weng\n",
      "110        virus diseases     0.133569  Chunhua Weng\n",
      "111              vomiting     0.015714  Chunhua Weng\n",
      "\n",
      "[112 rows x 3 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.30s/it]\n"
     ]
    }
   ],
   "execution_count": 348
  },
  {
   "cell_type": "code",
   "id": "45d37c6f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-20T22:39:35.850595Z",
     "start_time": "2025-11-20T22:39:35.840313Z"
    }
   },
   "source": [
    "df_summary = combine_research_focus_summaries(\n",
    "    directory=directory,\n",
    "    postfix_hd=\"HealthDomain\",\n",
    "    postfix_m=\"Method\",\n",
    "    output_excel=\"Research_summary_byMesh.xlsx\"\n",
    ")\n",
    "\n",
    "df_summary.head()\n"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  Researcher_name                                 Research_direction\n",
       "0    Chunhua Weng  This researcher mainly focused on understandin..."
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Researcher_name</th>\n",
       "      <th>Research_direction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Chunhua Weng</td>\n",
       "      <td>This researcher mainly focused on understandin...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 349,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 349
  },
  {
   "cell_type": "code",
   "id": "21d18de0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-20T22:39:35.941462Z",
     "start_time": "2025-11-20T22:39:35.938993Z"
    }
   },
   "source": "'''This researcher mainly focused on understanding the mechanisms of behavior and behavioral sciences in relation to pathological conditions, including infections, neoplasms, and various diseases such as virus, lung, respiratory tract, nutritional, and metabolic diseases, with an emphasis on psychology and RNA virus infections.\\nThis researcher has mainly contributed to integrating information science, health services administration, and medical informatics to enhance health care quality, access, and evaluation through advanced computing methodologies, epidemiologic methods, and artificial intelligence, while considering population characteristics, public health, and social sciences to improve patient care management, clinical studies, and health care delivery systems.'''",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'This researcher mainly focused on understanding the mechanisms of behavior and behavioral sciences in relation to pathological conditions, including infections, neoplasms, and various diseases such as respiratory, nutritional, metabolic, and RNA virus infections, with an emphasis on psychology and virus-related lung diseases.\\nThis researcher has mainly contributed to integrating information science, health services administration, and informatics to enhance health care quality, access, and evaluation through advanced methodologies such as artificial intelligence, data mining, and computational biology, while considering population characteristics, epidemiologic methods, and social sciences to improve public health outcomes and health care delivery systems.'"
      ]
     },
     "execution_count": 350,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 350
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
